# WA-06 ‚Äî Processamento de √Åudio e Imagem via WhatsApp

## üìã CONTEXTO

O LA Studio Manager tem um agente WhatsApp funcional (WA-01 a WA-05) que processa mensagens de **texto** via NLP, executa a√ß√µes no Kanban/Calend√°rio, responde queries, mant√©m mem√≥ria epis√≥dica, e envia relat√≥rios automatizados.

Agora precisamos que o agente tamb√©m entenda **√°udio** (mensagens de voz) e **imagem** (fotos, prints, encaminhamentos).

### Stack Atual
- **Supabase Edge Functions** (Deno/TypeScript)
- **UAZAPI** (WhatsApp API): `https://lamusic.uazapi.com`
- **Edge Function principal**: `process-whatsapp-message` (v15)
- **Arquivos existentes**: index.ts, nlp-classifier.ts, action-executor.ts, query-handler.ts, memory-manager.ts

### Refer√™ncia Comprovada
O projeto **Personal Finance (DriveCFO)** j√° implementou √°udio e imagem com sucesso usando a mesma stack UAZAPI + Supabase. Os payloads abaixo s√£o **reais e confirmados em produ√ß√£o**.

---

## üéØ OBJETIVO

1. **√Åudio**: Usu√°rio envia mensagem de voz ‚Üí UAZAPI transcreve ‚Üí texto vai pro NLP ‚Üí a√ß√£o executada
2. **Imagem**: Usu√°rio envia foto/print ‚Üí UAZAPI baixa ‚Üí Vision AI interpreta ‚Üí comando extra√≠do ‚Üí a√ß√£o executada  
3. **Encaminhamento**: Usu√°rio encaminha √°udio/imagem de outra pessoa ‚Üí mesmo fluxo funciona

---

## üì¶ PAYLOADS REAIS DA UAZAPI (Confirmados em Produ√ß√£o)

### Payload de Texto (refer√™ncia)
```json
{
  "BaseUrl": "https://lamusic.uazapi.com",
  "EventType": "messages",
  "token": "<instance_token>",
  "owner": "5521981278047",
  "instanceName": "DriveCFO",
  "message": {
    "chatid": "5521981278047@s.whatsapp.net",
    "messageid": "AC2D3CE35233FB7A23897ED6CB569EDE",
    "messageType": "Conversation",
    "type": "text",
    "fromMe": false,
    "sender": "5521981278047@s.whatsapp.net",
    "senderName": "Luciano Alf",
    "messageTimestamp": 1763642580000,
    "content": "Teste Uazapi",
    "text": "Teste Uazapi",
    "mediaType": "",
    "wasSentByApi": false
  },
  "chat": {
    "phone": "+55 21 98127-8047",
    "wa_chatid": "5521981278047@s.whatsapp.net",
    "wa_name": "Luciano Alf"
  }
}
```

### Payload de √Åudio / Mensagem de Voz (PTT)
```json
{
  "BaseUrl": "https://lamusic.uazapi.com",
  "EventType": "messages",
  "token": "<instance_token>",
  "owner": "5521981278047",
  "message": {
    "chatid": "5521981278047@s.whatsapp.net",
    "messageid": "AC648E70B1841544C9725B0721823987",
    "messageType": "AudioMessage",
    "type": "media",
    "mediaType": "ptt",
    "fromMe": false,
    "sender": "5521981278047@s.whatsapp.net",
    "senderName": "Luciano Alf",
    "messageTimestamp": 1763554994000,
    "content": {
      "URL": "https://mmg.whatsapp.net/v/t62.7117-24/...",
      "mimetype": "audio/ogg; codecs=opus",
      "PTT": true,
      "seconds": 52,
      "fileLength": 109266,
      "mediaKey": "uzM2UFyuVA6k0GTAZVYGfC9gH0Bczw3ZSW7rKnMn3uQ=",
      "fileEncSHA256": "hpiQeFMNPvXJoLmoVR68AIzLXp70LbcEoctKVSdMA04=",
      "directPath": "/v/t62.7117-24/...",
      "mediaKeyTimestamp": 1763554943,
      "contextInfo": {}
    },
    "text": "",
    "wasSentByApi": false
  },
  "chat": {
    "phone": "+55 21 98127-8047",
    "wa_chatid": "5521981278047@s.whatsapp.net",
    "wa_name": "Luciano Alf"
  }
}
```

### Payload de Imagem
```json
{
  "BaseUrl": "https://lamusic.uazapi.com",
  "EventType": "messages",
  "message": {
    "chatid": "5521981278047@s.whatsapp.net",
    "messageid": "AB1234567890ABCDEF",
    "messageType": "ImageMessage",
    "type": "media",
    "mediaType": "image",
    "fromMe": false,
    "sender": "5521981278047@s.whatsapp.net",
    "senderName": "Luciano Alf",
    "messageTimestamp": 1763642580000,
    "content": {
      "URL": "https://mmg.whatsapp.net/v/t62.7118-24/...",
      "mimetype": "image/jpeg",
      "fileLength": 45678,
      "height": 1280,
      "width": 960,
      "mediaKey": "...",
      "fileEncSHA256": "...",
      "directPath": "/v/t62.7118-24/...",
      "mediaKeyTimestamp": 1763642500,
      "caption": "Olha esse card",
      "contextInfo": {}
    },
    "text": "Olha esse card",
    "wasSentByApi": false
  },
  "chat": {
    "phone": "+55 21 98127-8047",
    "wa_chatid": "5521981278047@s.whatsapp.net",
    "wa_name": "Luciano Alf"
  }
}
```

### Campos Cr√≠ticos para Detec√ß√£o de Tipo

```typescript
// Detec√ß√£o do tipo de mensagem
const messageType = payload.message.messageType; // "Conversation" | "AudioMessage" | "ImageMessage" | "ExtendedTextMessage"
const type = payload.message.type;               // "text" | "media"
const mediaType = payload.message.mediaType;     // "" | "ptt" | "image" | "document" | "video"

// √Åudio
const isAudio = (
  messageType === 'AudioMessage' || 
  type === 'media' && mediaType === 'ptt'
);

// Imagem
const isImage = (
  messageType === 'ImageMessage' ||
  type === 'media' && mediaType === 'image'
);

// Texto
const isText = (
  messageType === 'Conversation' || 
  messageType === 'ExtendedTextMessage' ||
  type === 'text'
);

// Caption de imagem (texto que acompanha a foto)
const caption = payload.message.text || '';

// ID da mensagem para download
const messageId = payload.message.messageid;
```

---

## üîß ENDPOINT UAZAPI: Download + Transcri√ß√£o

### POST /message/download

Este √© o endpoint chave. Ele faz **download E transcri√ß√£o** de m√≠dia.

```typescript
// BASE
const UAZAPI_BASE_URL = Deno.env.get('UAZAPI_BASE_URL'); // https://lamusic.uazapi.com
const UAZAPI_TOKEN = Deno.env.get('UAZAPI_TOKEN');

// HEADERS para todas as chamadas UAZAPI
const headers = {
  'Content-Type': 'application/json',
  'token': UAZAPI_TOKEN
};
```

#### Para √Åudio ‚Äî Transcri√ß√£o Autom√°tica
```typescript
// Pedir √† UAZAPI para baixar o √°udio E transcrever via Whisper (OpenAI)
const response = await fetch(`${UAZAPI_BASE_URL}/message/download`, {
  method: 'POST',
  headers,
  body: JSON.stringify({
    id: messageId,        // ID da mensagem do webhook
    transcribe: true,     // ‚Üê UAZAPI transcreve via Whisper automaticamente
    generate_mp3: true    // Retorna MP3 (opcional, padr√£o true)
  })
});

const result = await response.json();
// result = {
//   fileURL: "https://lamusic.uazapi.com/files/arquivo.mp3",
//   mimetype: "audio/mpeg",
//   transcription: "Cria um card urgente para revisar o contrato do evento de s√°bado"
// }

const transcribedText = result.transcription; // ‚Üê Texto pronto para o NLP
```

**IMPORTANTE**: A UAZAPI usa a OpenAI API Key que j√° est√° salva na inst√¢ncia para transcri√ß√£o Whisper. N√£o precisa enviar a key em cada chamada.

#### Para Imagem ‚Äî Download em Base64
```typescript
// Baixar imagem como base64 para enviar ao Vision AI
const response = await fetch(`${UAZAPI_BASE_URL}/message/download`, {
  method: 'POST',
  headers,
  body: JSON.stringify({
    id: messageId,        // ID da mensagem
    return_base64: true,  // ‚Üê Retorna conte√∫do em base64
    return_link: true     // Tamb√©m gera URL p√∫blica (opcional)
  })
});

const result = await response.json();
// result = {
//   fileURL: "https://lamusic.uazapi.com/files/imagem.jpg",
//   mimetype: "image/jpeg",
//   base64Data: "/9j/4AAQSkZJRgABAQ..."  // ‚Üê Base64 da imagem
// }

const imageBase64 = result.base64Data;
const imageMimetype = result.mimetype;
```

---

## üìÅ ARQUIVOS A CRIAR

### 1. `audio-handler.ts` ‚Äî Processamento de √Åudio

```
supabase/functions/process-whatsapp-message/audio-handler.ts
```

```typescript
// =============================================================================
// AUDIO-HANDLER.TS ‚Äî Transcri√ß√£o de √Åudio via UAZAPI + Whisper
// LA Studio Manager ‚Äî WA-06
// =============================================================================

const UAZAPI_BASE_URL = Deno.env.get('UAZAPI_BASE_URL')!;
const UAZAPI_TOKEN = Deno.env.get('UAZAPI_TOKEN')!;

export interface AudioResult {
  success: boolean;
  transcription?: string;
  duration_seconds?: number;
  error?: string;
}

/**
 * Transcreve mensagem de √°udio via UAZAPI (que usa Whisper internamente)
 * 
 * Fluxo: WhatsApp Audio ‚Üí UAZAPI Download+Transcribe ‚Üí Texto
 */
export async function transcribeAudio(messageId: string): Promise<AudioResult> {
  console.log(`üé§ [AUDIO] Transcrevendo √°udio: ${messageId}`);
  
  try {
    const response = await fetch(`${UAZAPI_BASE_URL}/message/download`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'token': UAZAPI_TOKEN
      },
      body: JSON.stringify({
        id: messageId,
        transcribe: true,
        generate_mp3: true
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`‚ùå [AUDIO] UAZAPI error ${response.status}: ${errorText}`);
      return { success: false, error: `UAZAPI retornou ${response.status}: ${errorText}` };
    }

    const result = await response.json();

    if (!result.transcription || result.transcription.trim() === '') {
      console.warn('‚ö†Ô∏è [AUDIO] Transcri√ß√£o vazia');
      return { success: false, error: 'Transcri√ß√£o vazia ‚Äî √°udio muito curto ou inaud√≠vel' };
    }

    console.log(`‚úÖ [AUDIO] Transcri√ß√£o: "${result.transcription}"`);
    
    return {
      success: true,
      transcription: result.transcription.trim()
    };

  } catch (error) {
    console.error('‚ùå [AUDIO] Exce√ß√£o:', error);
    return { success: false, error: `Erro ao transcrever: ${error.message}` };
  }
}
```

---

### 2. `image-handler.ts` ‚Äî Processamento de Imagem

```
supabase/functions/process-whatsapp-message/image-handler.ts
```

```typescript
// =============================================================================
// IMAGE-HANDLER.TS ‚Äî Leitura de Imagem via UAZAPI + OpenAI Vision
// LA Studio Manager ‚Äî WA-06
// =============================================================================

const UAZAPI_BASE_URL = Deno.env.get('UAZAPI_BASE_URL')!;
const UAZAPI_TOKEN = Deno.env.get('UAZAPI_TOKEN')!;
const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY')!;

// =============================================================================
// TIPOS
// =============================================================================

export type ImageContentType = 
  | 'kanban_screenshot'    // Print de quadro kanban/trello/notion
  | 'event_poster'         // Cartaz/flyer de evento
  | 'document_photo'       // Foto de documento/contrato
  | 'schedule_photo'       // Foto de cronograma/agenda
  | 'receipt_invoice'      // Recibo/nota fiscal
  | 'general'              // Outro conte√∫do
  | 'unreadable';          // N√£o conseguiu ler

export interface ImageAnalysis {
  success: boolean;
  content_type: ImageContentType;
  extracted_text: string;          // Texto principal extra√≠do
  structured_data?: {              // Dados estruturados quando poss√≠vel
    title?: string;
    date?: string;
    items?: string[];
    amount?: number;
    people?: string[];
    location?: string;
  };
  suggested_action?: string;       // Sugest√£o de comando para o NLP
  confidence: 'high' | 'medium' | 'low';
  error?: string;
}

// =============================================================================
// DOWNLOAD DA IMAGEM VIA UAZAPI
// =============================================================================

async function downloadImage(messageId: string): Promise<{ base64: string; mimetype: string } | null> {
  console.log(`üì• [IMAGE] Baixando imagem: ${messageId}`);
  
  try {
    const response = await fetch(`${UAZAPI_BASE_URL}/message/download`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'token': UAZAPI_TOKEN
      },
      body: JSON.stringify({
        id: messageId,
        return_base64: true,
        return_link: false    // N√£o precisa de link p√∫blico, s√≥ base64
      })
    });

    if (!response.ok) {
      console.error(`‚ùå [IMAGE] UAZAPI error: ${response.status}`);
      return null;
    }

    const result = await response.json();
    
    if (!result.base64Data) {
      console.error('‚ùå [IMAGE] Base64 vazio na resposta');
      return null;
    }

    return {
      base64: result.base64Data,
      mimetype: result.mimetype || 'image/jpeg'
    };

  } catch (error) {
    console.error('‚ùå [IMAGE] Erro ao baixar:', error);
    return null;
  }
}

// =============================================================================
// AN√ÅLISE VIA OPENAI VISION (GPT-4o)
// =============================================================================

export async function analyzeImage(
  messageId: string,
  caption?: string
): Promise<ImageAnalysis> {
  console.log(`üîç [IMAGE] Analisando imagem: ${messageId}, caption: "${caption || ''}"`);

  // 1. Baixar imagem
  const imageData = await downloadImage(messageId);
  if (!imageData) {
    return {
      success: false,
      content_type: 'unreadable',
      extracted_text: '',
      confidence: 'low',
      error: 'N√£o foi poss√≠vel baixar a imagem'
    };
  }

  // 2. Enviar para OpenAI Vision
  try {
    const systemPrompt = `Voc√™ √© um assistente de gest√£o de projetos da LA Music (escola de m√∫sica).
Analise a imagem enviada e extraia informa√ß√µes relevantes.

CONTEXTO DO SISTEMA:
- LA Music usa um sistema Kanban para gerenciar projetos (cards com t√≠tulo, descri√ß√£o, respons√°vel, prazo)
- H√° um calend√°rio de eventos (shows, apresenta√ß√µes, ensaios)
- Os projetos s√£o da √°rea de educa√ß√£o musical

RESPONDA SEMPRE EM JSON com esta estrutura:
{
  "content_type": "kanban_screenshot|event_poster|document_photo|schedule_photo|receipt_invoice|general|unreadable",
  "extracted_text": "resumo do conte√∫do principal da imagem",
  "structured_data": {
    "title": "t√≠tulo se identific√°vel",
    "date": "data se identific√°vel (YYYY-MM-DD)",
    "items": ["lista de itens se aplic√°vel"],
    "amount": null,
    "people": ["nomes de pessoas se identific√°veis"],
    "location": "local se identific√°vel"
  },
  "suggested_action": "sugest√£o de comando que o usu√°rio poderia querer executar no sistema. Ex: 'criar card: Ensaio Geral com prazo 15/03' ou 'agendar evento: Show de Natal dia 20/12' ou null se n√£o aplic√°vel",
  "confidence": "high|medium|low"
}

Se houver uma legenda/caption junto com a imagem, considere-a como contexto adicional para entender a inten√ß√£o do usu√°rio.`;

    const userContent: any[] = [
      {
        type: 'image_url',
        image_url: {
          url: `data:${imageData.mimetype};base64,${imageData.base64}`,
          detail: 'high'
        }
      }
    ];

    if (caption) {
      userContent.push({
        type: 'text',
        text: `Legenda do usu√°rio: "${caption}"`
      });
    } else {
      userContent.push({
        type: 'text',
        text: 'O usu√°rio enviou esta imagem sem legenda. Analise o conte√∫do.'
      });
    }

    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userContent }
        ],
        max_tokens: 1000,
        temperature: 0.2
      })
    });

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text();
      console.error(`‚ùå [IMAGE] OpenAI Vision error: ${openaiResponse.status} - ${errorText}`);
      return {
        success: false,
        content_type: 'unreadable',
        extracted_text: '',
        confidence: 'low',
        error: `OpenAI retornou ${openaiResponse.status}`
      };
    }

    const openaiResult = await openaiResponse.json();
    const responseText = openaiResult.choices?.[0]?.message?.content || '';

    // Parse JSON da resposta
    const jsonMatch = responseText.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.warn('‚ö†Ô∏è [IMAGE] Resposta n√£o cont√©m JSON v√°lido');
      return {
        success: true,
        content_type: 'general',
        extracted_text: responseText,
        confidence: 'low'
      };
    }

    const analysis = JSON.parse(jsonMatch[0]);
    
    console.log(`‚úÖ [IMAGE] An√°lise: tipo=${analysis.content_type}, confian√ßa=${analysis.confidence}`);
    console.log(`üìù [IMAGE] Texto: "${analysis.extracted_text}"`);
    if (analysis.suggested_action) {
      console.log(`üí° [IMAGE] A√ß√£o sugerida: "${analysis.suggested_action}"`);
    }

    return {
      success: true,
      content_type: analysis.content_type || 'general',
      extracted_text: analysis.extracted_text || '',
      structured_data: analysis.structured_data || {},
      suggested_action: analysis.suggested_action || undefined,
      confidence: analysis.confidence || 'medium'
    };

  } catch (error) {
    console.error('‚ùå [IMAGE] Erro na an√°lise:', error);
    return {
      success: false,
      content_type: 'unreadable',
      extracted_text: '',
      confidence: 'low',
      error: `Erro ao analisar: ${error.message}`
    };
  }
}
```

---

## üìù MODIFICAR: `index.ts` ‚Äî Integrar √Åudio e Imagem

### Importa√ß√µes a adicionar (topo do arquivo)

```typescript
import { transcribeAudio } from './audio-handler.ts';
import { analyzeImage } from './image-handler.ts';
```

### L√≥gica de detec√ß√£o e roteamento (ap√≥s extrair o payload)

No `index.ts`, **AP√ìS** a extra√ß√£o do payload e valida√ß√£o do usu√°rio, **ANTES** da chamada ao NLP classifier, adicionar a detec√ß√£o de tipo de m√≠dia:

```typescript
// =============================================================================
// DETEC√á√ÉO DO TIPO DE MENSAGEM
// =============================================================================

const messageType = payload.message?.messageType || '';
const mediaType = payload.message?.mediaType || '';
const msgType = payload.message?.type || 'text';
const messageId = payload.message?.messageid || '';
const rawText = payload.message?.text || '';

// Flags de tipo
const isAudio = (
  messageType === 'AudioMessage' ||
  (msgType === 'media' && mediaType === 'ptt')
);

const isImage = (
  messageType === 'ImageMessage' ||
  (msgType === 'media' && mediaType === 'image')
);

const isText = (
  messageType === 'Conversation' ||
  messageType === 'ExtendedTextMessage' ||
  msgType === 'text'
);

let userMessage = rawText; // Texto final que vai pro NLP
let imageAnalysis = null;  // Resultado da an√°lise de imagem (se houver)

// =============================================================================
// PROCESSAR √ÅUDIO
// =============================================================================
if (isAudio) {
  console.log(`üé§ [WA-06] Mensagem de √°udio detectada: ${messageId}`);
  
  const audioResult = await transcribeAudio(messageId);
  
  if (!audioResult.success || !audioResult.transcription) {
    // Responder que n√£o entendeu o √°udio
    await sendWhatsAppMessage(phone, 
      'üé§ N√£o consegui entender o √°udio. Pode repetir ou digitar a mensagem?'
    );
    return new Response(JSON.stringify({ success: true, type: 'audio_failed' }), {
      headers: { 'Content-Type': 'application/json' }
    });
  }
  
  // Usar texto transcrito como se fosse mensagem de texto
  userMessage = audioResult.transcription;
  console.log(`üìù [WA-06] √Åudio transcrito: "${userMessage}"`);
  
  // Continua o fluxo normal abaixo com userMessage...
}

// =============================================================================
// PROCESSAR IMAGEM
// =============================================================================
if (isImage) {
  console.log(`üì∑ [WA-06] Mensagem de imagem detectada: ${messageId}`);
  
  const caption = rawText || ''; // Legenda que acompanha a foto
  imageAnalysis = await analyzeImage(messageId, caption);
  
  if (!imageAnalysis.success) {
    await sendWhatsAppMessage(phone,
      'üì∑ N√£o consegui analisar a imagem. Pode descrever o que precisa?'
    );
    return new Response(JSON.stringify({ success: true, type: 'image_failed' }), {
      headers: { 'Content-Type': 'application/json' }
    });
  }
  
  // Se o Vision sugeriu uma a√ß√£o, usar como mensagem pro NLP
  if (imageAnalysis.suggested_action) {
    userMessage = imageAnalysis.suggested_action;
    console.log(`üí° [WA-06] Usando a√ß√£o sugerida do Vision: "${userMessage}"`);
  } 
  // Se tem caption, combinar caption + contexto da imagem
  else if (caption) {
    userMessage = `${caption} [Contexto da imagem: ${imageAnalysis.extracted_text}]`;
    console.log(`üìù [WA-06] Caption + contexto: "${userMessage}"`);
  }
  // Sem caption e sem a√ß√£o ‚Äî s√≥ descrever o que viu
  else {
    // Responder com descri√ß√£o e perguntar o que fazer
    const description = imageAnalysis.extracted_text || 'Recebi a imagem.';
    await sendWhatsAppMessage(phone,
      `üì∑ ${description}\n\nO que voc√™ gostaria de fazer com essa informa√ß√£o?`
    );
    return new Response(JSON.stringify({ success: true, type: 'image_described' }), {
      headers: { 'Content-Type': 'application/json' }
    });
  }
  
  // Continua o fluxo normal abaixo com userMessage...
}

// =============================================================================
// FLUXO NORMAL ‚Äî NLP CLASSIFIER (usa userMessage que pode ser texto, transcri√ß√£o ou a√ß√£o da imagem)
// =============================================================================
// ... c√≥digo existente do NLP classifier usando 'userMessage' ...
```

---

## üóÑÔ∏è BANCO DE DADOS ‚Äî Log de M√≠dias Processadas

### Migration: `wa06_media_processing_log.sql`

```sql
-- =============================================================================
-- WA-06: Log de processamento de m√≠dias (√°udio/imagem)
-- =============================================================================

-- Tabela para registrar processamentos de m√≠dia
CREATE TABLE IF NOT EXISTS wa_media_processing_log (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  whatsapp_message_id TEXT NOT NULL,
  media_type TEXT NOT NULL CHECK (media_type IN ('audio', 'image', 'video', 'document')),
  
  -- Resultado do processamento
  processing_status TEXT NOT NULL DEFAULT 'pending' 
    CHECK (processing_status IN ('pending', 'processing', 'success', 'failed')),
  
  -- Para √°udio
  transcription TEXT,
  audio_duration_seconds INTEGER,
  
  -- Para imagem
  image_content_type TEXT, -- kanban_screenshot, event_poster, etc.
  extracted_text TEXT,
  structured_data JSONB,
  suggested_action TEXT,
  analysis_confidence TEXT CHECK (analysis_confidence IN ('high', 'medium', 'low')),
  
  -- Rastreamento
  processing_time_ms INTEGER,     -- Quanto tempo levou o processamento
  ai_model_used TEXT,             -- whisper, gpt-4o, gemini, etc.
  error_message TEXT,
  
  created_at TIMESTAMPTZ DEFAULT now()
);

-- Index para busca por usu√°rio
CREATE INDEX idx_media_log_user ON wa_media_processing_log(user_id, created_at DESC);
CREATE INDEX idx_media_log_status ON wa_media_processing_log(processing_status);

-- RLS
ALTER TABLE wa_media_processing_log ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Admins can manage media logs"
  ON wa_media_processing_log
  FOR ALL
  USING (
    EXISTS (
      SELECT 1 FROM user_roles 
      WHERE user_id = auth.uid() 
      AND role IN ('admin', 'super_admin')
    )
  );

-- Service role tem acesso total (Edge Functions)
CREATE POLICY "Service role full access on media logs"
  ON wa_media_processing_log
  FOR ALL
  USING (auth.role() = 'service_role');

COMMENT ON TABLE wa_media_processing_log IS 'WA-06: Log de processamento de m√≠dias via WhatsApp';
```

---

## üîÑ FLUXO COMPLETO ‚Äî DIAGRAMAS

### Fluxo de √Åudio
```
Usu√°rio envia √°udio (PTT)
       ‚îÇ
       ‚ñº
  UAZAPI Webhook ‚Üí Edge Function index.ts
       ‚îÇ
       ‚ñº
  Detecta: messageType === "AudioMessage"
       ‚îÇ
       ‚ñº
  audio-handler.ts ‚Üí POST /message/download { id, transcribe: true }
       ‚îÇ
       ‚ñº
  UAZAPI baixa √°udio ‚Üí envia pro Whisper ‚Üí retorna transcri√ß√£o
       ‚îÇ
       ‚ñº
  userMessage = transcription
       ‚îÇ
       ‚ñº
  NLP Classifier ‚Üí Action Executor ‚Üí Resposta WhatsApp
       ‚îÇ
       ‚ñº
  Log em wa_media_processing_log
```

### Fluxo de Imagem
```
Usu√°rio envia imagem (com ou sem legenda)
       ‚îÇ
       ‚ñº
  UAZAPI Webhook ‚Üí Edge Function index.ts
       ‚îÇ
       ‚ñº
  Detecta: messageType === "ImageMessage"
       ‚îÇ
       ‚ñº
  image-handler.ts ‚Üí POST /message/download { id, return_base64: true }
       ‚îÇ
       ‚ñº
  UAZAPI baixa imagem ‚Üí retorna base64
       ‚îÇ
       ‚ñº
  OpenAI GPT-4o Vision ‚Üí analisa imagem ‚Üí extrai dados + sugere a√ß√£o
       ‚îÇ
       ‚îú‚îÄ‚îÄ TEM a√ß√£o sugerida? ‚Üí userMessage = suggested_action ‚Üí NLP
       ‚îú‚îÄ‚îÄ TEM caption?       ‚Üí userMessage = caption + contexto ‚Üí NLP
       ‚îî‚îÄ‚îÄ SEM nada?          ‚Üí Descreve imagem e pergunta o que fazer
       ‚îÇ
       ‚ñº
  Log em wa_media_processing_log
```

### Fluxo de Encaminhamento
```
Usu√°rio encaminha √°udio/imagem de outra pessoa
       ‚îÇ
       ‚ñº
  Payload UAZAPI √© ID√äNTICO (mesmo messageType, mesmo mediaType)
  A diferen√ßa est√° no campo contextInfo que pode ter:
  - isForwarded: true
  - forwardingScore: N
       ‚îÇ
       ‚ñº
  O fluxo √© EXATAMENTE o mesmo ‚Äî n√£o precisa de tratamento especial
  O √°udio √© transcrito / a imagem √© analisada normalmente
```

---

## ‚öôÔ∏è VARI√ÅVEIS DE AMBIENTE NECESS√ÅRIAS

Verificar que estas env vars existem no Supabase:

```bash
# J√° devem existir do WA-01:
UAZAPI_BASE_URL=https://lamusic.uazapi.com
UAZAPI_TOKEN=<token_da_instancia>

# Para OpenAI Vision (imagens):
OPENAI_API_KEY=<key>
# A mesma key √© usada pela UAZAPI para Whisper (j√° configurada na inst√¢ncia)
```

**NOTA**: A UAZAPI usa a `openai_apikey` salva na inst√¢ncia para transcri√ß√£o Whisper. Se a chave N√ÉO estiver salva, pode ser passada no request: `{ id, transcribe: true, openai_apikey: "sk-..." }`. Por√©m, ao enviar uma vez, ela fica salva na inst√¢ncia para chamadas futuras.

---

## üß™ TESTES

### Teste 1: √Åudio Simples
```
Enviar via WhatsApp: üé§ "Cria um card urgente para revisar contrato do evento de s√°bado"
Esperado: Card criado no Kanban com t√≠tulo similar
```

### Teste 2: √Åudio com Consulta
```
Enviar via WhatsApp: üé§ "Quantos cards est√£o pendentes?"
Esperado: Resposta com contagem de cards pendentes
```

### Teste 3: Imagem com Caption
```
Enviar via WhatsApp: üì∑ Foto de um cartaz de show + caption "Agenda esse evento"
Esperado: Evento criado no calend√°rio com dados extra√≠dos do cartaz
```

### Teste 4: Imagem sem Caption
```
Enviar via WhatsApp: üì∑ Print de tela de um quadro kanban (sem texto)
Esperado: Bot descreve o que viu e pergunta o que fazer
```

### Teste 5: √Åudio Encaminhado
```
Encaminhar √°udio de outra pessoa: üé§ "Preciso confirmar o local do ensaio de ter√ßa"
Esperado: √Åudio transcrito e processado normalmente
```

### Teste 6: Imagem Encaminhada
```
Encaminhar foto de um recibo/contrato
Esperado: Imagem analisada, dados extra√≠dos, pergunta o que fazer
```

### Teste 7: √Åudio Inaud√≠vel / Imagem Ileg√≠vel
```
Enviar √°udio muito curto (< 1s) ou imagem toda preta
Esperado: Mensagem amig√°vel pedindo para repetir
```

---

## üîí TRATAMENTO DE ERROS

1. **UAZAPI indispon√≠vel**: Responder "Estou com dificuldade t√©cnica, tente digitar a mensagem"
2. **Whisper falha na transcri√ß√£o**: Responder "N√£o entendi o √°udio, pode repetir ou digitar?"
3. **OpenAI Vision falha**: Responder "N√£o consegui analisar a imagem, pode descrever?"
4. **√Åudio muito longo (> 5 min)**: Processar normalmente mas avisar que pode demorar
5. **Imagem muito pesada**: UAZAPI lida com isso, mas se der timeout, avisar o usu√°rio
6. **Rate limit OpenAI**: Implementar retry com backoff (max 2 tentativas)

---

## üìä LOGGING NO wa_media_processing_log

Registrar TODA m√≠dia processada para an√°lise futura:

```typescript
// No final do processamento de √°udio ou imagem, salvar log:
async function logMediaProcessing(
  supabase: SupabaseClient,
  data: {
    user_id: string;
    whatsapp_message_id: string;
    media_type: 'audio' | 'image';
    processing_status: 'success' | 'failed';
    transcription?: string;
    audio_duration_seconds?: number;
    image_content_type?: string;
    extracted_text?: string;
    structured_data?: object;
    suggested_action?: string;
    analysis_confidence?: string;
    processing_time_ms: number;
    ai_model_used: string;
    error_message?: string;
  }
) {
  const { error } = await supabase
    .from('wa_media_processing_log')
    .insert(data);
  
  if (error) {
    console.error('‚ö†Ô∏è Erro ao salvar log de m√≠dia:', error);
  }
}
```

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

- [ ] Criar `audio-handler.ts`
- [ ] Criar `image-handler.ts`
- [ ] Migration `wa06_media_processing_log.sql`
- [ ] Modificar `index.ts` ‚Äî detec√ß√£o de tipo + roteamento
- [ ] Integrar logging de m√≠dia
- [ ] Verificar env vars (UAZAPI_BASE_URL, UAZAPI_TOKEN, OPENAI_API_KEY)
- [ ] Deploy Edge Function (`supabase functions deploy process-whatsapp-message`)
- [ ] Testar √°udio simples
- [ ] Testar √°udio com consulta
- [ ] Testar imagem com caption
- [ ] Testar imagem sem caption
- [ ] Testar encaminhamentos
- [ ] Testar erros (√°udio inaud√≠vel, imagem ileg√≠vel)
- [ ] Verificar logs na tabela wa_media_processing_log

---

## üìå NOTAS FINAIS

1. **N√ÉO precisa de Edge Function separada** ‚Äî tudo roda dentro de `process-whatsapp-message` com dois novos m√≥dulos (audio-handler.ts e image-handler.ts)

2. **A UAZAPI faz o trabalho pesado** ‚Äî ela baixa o √°udio encriptado do WhatsApp, decodifica, converte pra MP3, e transcreve via Whisper. N√≥s s√≥ chamamos `/message/download` com `transcribe: true`.

3. **Encaminhamentos funcionam automaticamente** ‚Äî o payload √© id√™ntico, a UAZAPI n√£o diferencia mensagem original de encaminhada no download.

4. **GPT-4o √© prefer√≠vel ao Gemini Vision** para este caso porque j√° temos a API Key da OpenAI configurada e o modelo tem excelente performance com screenshots de interfaces/documentos.

5. **O texto transcrito/extra√≠do segue o fluxo EXISTENTE** ‚Äî vai direto pro NLP Classifier ‚Üí Action Executor ‚Üí Response. Sem duplica√ß√£o de l√≥gica.